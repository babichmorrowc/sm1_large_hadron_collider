---
title: "Maximising AMS by classifying Higgs Boson Data - a love story"
author: "Kieran Morris, Cecina Babich Morrow and Daniella Montgomery"
date: "2023-11-07"
output:
  html_document: default
  pdf_document: default
---

```{r include = FALSE}
# devtools::install_github("babichmorrowc/higgiesmalls") # install our R package if necessary
library(higgiesmalls)
library(tidyverse)
library(here)
library(skimr)
library(ggplot2)
library(purrr)
library(ggpubr) #for ggarrange
library(DT) #datatables
library(cowplot)
```

```{r, echo = FALSE,include=FALSE,message = FALSE}
source(here("R/clean_data.R"))
summary_OfHiggs <- skim(higgs_data_na)
```


# The Method

As we have $31$-dimensional data we will perform preliminary analysis of the variables before running classification. The following is a loose structure of our method for tackling this problem:

1.  Eliminate any obviously redundant variables such as meta-data.
2.  Analyse and deal with any missing data.
3.  Remove variables which have minimal impact on classification.
4.  Perform a classification algorithm.
5.  Study the impact on the AMS.

# Preliminary Observations

## Types of Data

We have a few types of data to consider:

-   Variables `KaggleSet` and `KaggleWeight` can be ignored as they denote which data points were in the provided Kaggle challenge and their relative weights, which is irrelevant to us.

-   The discrete classification variable `Label` which takes values in $\{b,s\}$

-   The continuous variable `Weight`, which will be used to compute the AMS, and will not be used in classification.

-   The discrete variable `PRI_jet_num` denotes the amount of jets from each event and takes values in $\{0,1,2,3\}$.

-   We have multiple variables which are the angle of detection for some observation.

-   All other variables are either direct or indirect measurements and are continuous.

## Co-Dependency of Data

Since we are classifying, we want to remove any redundancies in our data, fortunately we have the following co-dependencies:

-   `PRI_jet_all_pt = PRI_jet_leading_pt + PRI_jet_subleading_pt`

-   `PRI_lep_pt = DER_pt_ratio_lep_tau*PRI_tau_pt`

-   Jet-related variables depend on `PRI_jet_num` (see next section for more)

We can either remove `PRI_jet_all_pt` or remove both `PRI_jet_leading_pt` and `PRI_jet_subleading_pt` to reduce the dimension by $1$ or $2$. This same idea can be applied to to the other (multiplicative) dependence. With these reductions we could remove up to $4$ dimensions from our data.

If we wish to be more liberal with our removal, we could throw out all jet related variables besides `PRI_jet_num` to remove $10$ more dimensions from our data. However this is assuming that the other jet variables have little impact on classification which has not been validated - yet.

# Missing Data

## What is missing and why?

Below are the variables which contain undefined values. By convention it was provided to use with values `-999` which is out of range for every observation.

```{r,echo = FALSE}
variables_WithError <- filter(yank(summary_OfHiggs,"numeric"), complete_rate != 1)
ve <- datatable(variables_WithError[1:3],options = list(pageLength = 11))
ve
```

Notice that every column besides `DER_mass_MMC` is a jet variable, and in those, we only have two values for `completion_rate`. In fact these correspond to different values of `PRI_jet_num`:

-   0 jets: All jet variables were missing data.

-   1 jet: only `PRI_leading_pt`,`PRI_leading_eta` and `PRI_leading_phi` have data.

-   2 or more jets: All jet variables have data.

The above result can be found in the handbook for the variables provided with the Kaggle challenge. Unfortunately `DER_mass_MMC` does not have such an explanation and may be a result of some event during measurement. However it is still assigned the same `-999` value as the other missing data.

## Impact of the Missing Data

Despite understanding the cause of (most of) our missing data, we still don't know the impactof it, the following section is dedicated to understanding the correlation between the missing data from each variable and its classification.

Below we compute the percentage of `NA` data in Background and Signal respectively. If this missing data is distributed uniformly across Background and Signal then the percentages should be very close.

```{r, echo = FALSE}
variables_WithError <- filter(summary_OfHiggs, complete_rate != 1)#Finding the columns which contain undefined elements

Background <- filter(higgs_data_na, Label == "b")[c(variables_WithError$skim_variable)]#filtering rows by background
Signal <- filter(higgs_data_na, Label =="s")[c(variables_WithError$skim_variable)]#filter rows by signal

missing_GivenB <- apply(Background,2,function(x){return(round(100*sum(is.na(x))/length(x),digits = 4))})#calculate percentage missing data for background and signal
missing_GivenS <- apply(Signal,2,function(x){return(round(100*sum(is.na(x))/length(x),digits = 4))})

df <- datatable(data.frame(missing_GivenS,missing_GivenB,missing_GivenB-missing_GivenS),col = c("Signal","Background","Difference"),caption = "% of Missing Background and Signal Data",options = list(pageLength = 11))

df
```

Notice that `Signal` consistently has $13-18 \%$ less missing data than `Background`. This means that in both the `DER_mass_MMC` and jet-variables cases, the amount of missing data is indicative of a classification. Meaning that including `-999` can help with classification and will not be removed.

# Variable Selection

## The Distributions

To get an understanding of the behavior of variable given their classification, we condition each variable on whether $y=b$ or $y=s$ respectively. The entire list can be found in the appendix but here are a few of note:

```{r, warning=FALSE,message = FALSE, echo = FALSE,fig.align="center",fig.width = 14,fig.height= 10}
source(here("R/variable_plots.R"))
density_plots <- lapply(cols_ToPlot,plots)
plot_sample_densities <- ggarrange(plotlist = density_plots,ncol = 2, nrow = 2, align = "v", common.legend = TRUE)
plot_sample_densities
```

Note that the data for these plots the variables have `NA` instead of `-999` for missing data, again see appendix for plots with `-999` included. Some key takeaways from these plots are:

-   We see that some these angle variables: `PRI_tau_phi`,`PRI_lep_phi`, `PRI_met_phi`,`PRI_jet_leading_phi`and `PRI_jet_subleading_phi` are approximately uniformly distributed and that there is very little variation between the classifications.

-   We have many distributions with distinct translations in their peaks: `DER_mass_MMC`,`DER_mass_transverse_met_lep`,`DER_mass_vis`,`PRI_tau_pt` and `DER_pt_ratio_lep_tau`.

-   We can see that many Jet-related variables are dominated by their `-999` values.

Looking at these plots, there are a few contenders for important variables for classification - the translated peaks are good examples. Additionally the angle variables which are largely uniform are likely to only constribute noise and not help with classification. 

Before we decide on our preferences of variables, we employ an information theoretic technique to measure the impact of each variable: The Mutual Information.
## Performing Mutual Information Tests

For each variable $V$ we compute its mutual information with `Label`, variables with high mutual information are better indicators for classification. We hope this will validate our observations from plotting the data.

Our results are below:
```{r,echo = FALSE, warning=FALSE,message = FALSE}
source(here("R/Mutual_Information.R"))

dt <- datatable(MI_Data_STORED_Ordered,col =c("Variable","Mutual Information"),
                options = list(pagelength=10))
dt
```

These results justify many of our direct observations from plotting the densities:

-   The variables with clear translational difference peaks (`DER_mass_MMC`,`DER_mass_transverse_met_lep`,`DER_mass_vis`,`PRI_tau_pt` and `DER_pt_ratio_lep_tau`) had very high mutual information. 

-   Additionally the mostly uniform variables ranked lowest in terms of mutual information.

-   Variables which were around the middle in terms of mutual Information typically had matching peaks but `b` had a higher variance.
## Principle Component Analysis

## Conclusions on Variable Selection
After considering our multiple ways of ranking these variables, we conclude that we will remove our variables heirarchically in the following order:

1) Including all variables

2) Removing all 4 algebraic co-dependencies (`PRI_jet_leading_pt`,`PRI_jet_subleading_pt`,`DER_pt_ratio_lep_tau`,`PRI_tau_pt`)

3) Removing the above and any uniform variables (`PRI_lep_phi`,`PRI_met_phi`,`PRI_tau_phi`)

4) Only use the top ten highest ranking mutual information variables (see above)

We note that one of our algebraic variables is `PRI_tau_pt`, which is in the top ten ranking - so that will be added back in. 

# Fisher Discriminant Analysis

FDA creates an embedding that tells us how linearly separated our data can possibly be by maximizing between class scatterness and minimizing within class scatterness. This can be a useful aid to find out whether a linear classifier is appropriate and can additionally be used to see how removing variables affects the separability of our data.

```{r,echo = FALSE, warning=FALSE,message = FALSE,fig.width = 14,fig.height= 5}
source(here("R/fda.R"))
FDA_all <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_all_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_all) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA with all variables") +
  theme_bw()
FDA_codep <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_drop_codep_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_drop_codep) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA without codependencies") +
  theme_bw()
FDA_codep_unif <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_drop_codep_unif_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_drop_codep_unif) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA without codependencies and uniform variables") +
  theme_bw()
FDA_mut_info <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_mut_info_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_mut_info) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA with highest mutual information") +
  theme_bw()
plot_grid(FDA_all,FDA_codep,FDA_codep_unif,FDA_mut_info,nrow = 2)
```

For these different FDA embeddings, we can compare the ratio between between class scatterness and within class scatterness:

```{r echo = FALSE}
datatable(
  data = data.frame(
    variables = c("All variables",
                  "Without codependencies",
                  "Without codependencies and uniform variables",
                  "Highest mutual information"),
    scatter_ratio = c(scatter_ratio_all,
                      scatter_ratio_drop_codep,
                      scatter_ratio_drop_codep_unif,
                      scatter_ratio_mut_info)
  ),
  colnames = c("Variables included", "Scatter ratio")
)
```

We find that removing variables slightly lowers the linear separability of the data, but in general the values are comparable. Based on the plots, we can conclude that it is not possible to achieve a high degree of linear separability between the signal and background events, indicating that a feature transform is most likely appropriate.


# Support Vector Machine

We divided our dataset into a training and testing split, training SVMs on the training data and finding the AMS on the testing data.

```{r echo = FALSE,warning = FALSE}
source(here("R/training_testing.R"))
```

By training SVMs with a linear kernel vs. a radial kernel on a 20% training set (using all predictor variables), we found that a radial kernel consistently yielded higher AMS:

```{r echo = FALSE}
fitted_svm_linear_all_20 <- readRDS(here("output/fitted_svm_linear_all_20.RDS"))
fitted_svm_radial_all_20 <- readRDS(here("output/fitted_svm_radial_all_20.RDS"))

linear_ams_20 <- approx_median_sig(predictions = fitted_svm_linear_all_20,
                                   labels = higgs_testing_20$Label,
                                   weights = testing_weights_20)
radial_ams_20 <- approx_median_sig(predictions = fitted_svm_radial_all_20,
                                   labels = higgs_testing_20$Label,
                                   weights = testing_weights_20)
```

```{r echo = FALSE}
datatable(
  data = data.frame(
    kernel = c("Linear",
               "Radial"),
    AMS = c(linear_ams_20,
            radial_ams_20)
  ),
  colnames = c("Kernel", "AMS")
)
```

Based on these results, along with the results of FDA indicating that the dataset is not linearly separable, we moved forward using a radial kernel. We performed 5-fold cross-validation over the 20% training set to tune the two hyperparameters using a grid search: cost and $\gamma$ (bandwidth). We allowed cost to take on the values 0.5, 1, and 2 and $\gamma$ to take on the values 0.01, 0.1, and 0.5.

## Support Vector Machine

We divided our dataset into a training and testing split, training SVMs on the training data and finding the AMS on the testing data.

```{r echo = FALSE, message=FALSE}
source(here("R/training_testing.R"))
```

By training SVMs with a linear kernel vs. a radial kernel on a 20% training set (using all predictor variables), we found that a radial kernel consistently yielded higher AMS:

```{r echo = FALSE}
fitted_svm_linear_all_20 <- readRDS(here("output/fitted_svm_linear_all_20.RDS"))
fitted_svm_radial_all_20 <- readRDS(here("output/fitted_svm_radial_all_20.RDS"))

linear_ams_20 <- approx_median_sig(predictions = fitted_svm_linear_all_20,
                                   labels = higgs_testing_20$Label,
                                   weights = testing_weights_20)
radial_ams_20 <- approx_median_sig(predictions = fitted_svm_radial_all_20,
                                   labels = higgs_testing_20$Label,
                                   weights = testing_weights_20)
```

```{r echo = FALSE}
datatable(
  data = data.frame(
    kernel = c("Linear",
               "Radial"),
    AMS = c(linear_ams_20,
            radial_ams_20)
  ),
  colnames = c("Kernel", "AMS")
)
```

Based on these results, along with the results of FDA indicating that the dataset is not linearly separable, we moved forward using a radial kernel. We performed 5-fold cross-validation over the 20% training set to tune the two hyperparameters using a grid search: cost and $\gamma$ (bandwidth). We allowed cost to take on the values 0.5, 1, and 2 and $\gamma$ to take on the values 0.01, 0.1, and 0.5. Tuning was performed using our function `ams_tune_parallel`, which modifies the `e1071::tune` function to maximise AMS and to conduct cross-validation in parallel, dramatically improving the performance of tuning compared to the original package.

Below are the results of the hyperparameter tuning using the three sets of variables: 1) Including all variables; 2) Removing the algebraic co-dependencies and uniformly distributed variables; 3) Using only the 10 variables with the highest mutual information.

```{r}
tune_params <- readRDS(here("output/tune_params.RDS"))
datatable(
  tune_params,
  colnames = c("Variables included",
               "Cost",
               "Gamma")
)
```

We then used the model using the best hyperparameter values from tuning to find the AMS value on the 80% testing dataset.

```{r echo = FALSE}
fitted_tuned_svm_radial_all <- readRDS(here("output/fitted_tuned_svm_radial_all_20.RDS"))
fitted_tuned_svm_radial_drop_codep_unif <- readRDS(here("output/fitted_tuned_svm_radial_drop_codep_unif_20_gc.RDS"))
fitted_tuned_svm_radial_mut_info <- readRDS(here("output/fitted_tuned_svm_radial_mut_info_20.RDS"))

all_ams <- approx_median_sig(predictions = fitted_tuned_svm_radial_all,
                             labels = higgs_testing_20$Label,
                             weights = testing_weights_20)
drop_codep_unif_ams <- approx_median_sig(predictions = fitted_tuned_svm_radial_drop_codep_unif,
                                         labels = higgs_testing_20$Label,
                                         weights = testing_weights_20)
mut_info_ams <- approx_median_sig(predictions = fitted_tuned_svm_radial_mut_info,
                                  labels = higgs_testing_20$Label,
                                  weights = testing_weights_20)
```

```{r echo = FALSE}
datatable(
  data = data.frame(
    kernel = c("All variables",
               "Without co-dependencies and uniform variables",
               "Highest mutual information"),
    AMS = c(all_ams,
            drop_codep_unif_ams,
            mut_info_ams)
  ),
  colnames = c("Variables included", "Testing AMS")
)
```

# Appendix


### Distributions with `-999` entries

```{r, warning=FALSE,message = FALSE, echo = FALSE,fig.align="center",fig.width = 14,fig.height = 35}
plot_list2 <- lapply(cols_ToPlot3,plots)
plot_sample_densities_orig <- ggarrange(plotlist = plot_list2,ncol = 2, nrow = 15, align = "v", common.legend = TRUE)

plot_sample_densities_orig
```

### Distributions with `NA` entries

```{r, warning=FALSE,message = FALSE, echo = FALSE,fig.align="center",fig.width = 14,fig.height = 35}
density_plots <- lapply(cols_ToPlot2,plots)
plot_sample_densities <- ggarrange(plotlist = density_plots,ncol = 2, nrow = 15, align = "v", common.legend = TRUE)
plot_sample_densities
```
