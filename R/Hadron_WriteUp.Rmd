---
title: "Maximising AMS by classifying Higgs Boson Data"
author: "Kieran Morris, Cecina Babich Morrow and Daniella Montgomery"
date: "2023-11-07"
output:
  html_document: default
  pdf_document: default
---

This RMarkdown document is a companion piece to a Latex document submitted detailing our work on this project. For discussion including references to other works and justification for the techniques and methods used, please refer to that document. This will be an indepth exploration of the statistical results and `R` code only.

The source code for this Rmarkdown and all annotated `R` code can be found in the following GitHub repository:
```{f}
https://github.com/babichmorrowc/sm1_large_hadron_collider
```

Additionally this project comes with a package which contains all necessary functions which can be downloaded via the following command in the `R` console:
```{r,eval = FALSE}
devtools::install_github("babichmorrowc/higgiesmalls")
```
```{r include = FALSE}
library(higgiesmalls)#import our package
library(tidyverse)#tidyverse
library(here)#file organisation
library(skimr)#summary data analysis
library(ggplot2)#ggplot
library(purrr)#tidyverse add on
library(ggpubr) #for ggarrange
library(DT) #datatables
library(cowplot)#another ggarrange
```

```{r, echo = FALSE,include=FALSE,message = FALSE}
source(here("R/clean_data.R"))
#Runs /clean_data, our file which tidies up the data 
summary_OfHiggs <- skim(higgs_data_na)
#using skim package to get a brief summary of the data including completion rate
```

# Preliminary Observations

Our data consists of events detected at the Large Hadron Collider which were classified as either Background (b) or Signal (s) - Signal being a detection of a higgs boson.

## Types of Data

We have a few types of data to consider:

-   Variables `KaggleSet` and `KaggleWeight` can be ignored as they denote which data points were in the provided Kaggle challenge and their relative weights, which is irrelevant to us.

-   The discrete classification variable `Label` which takes values in $\{b,s\}$

-   The continuous variable `Weight`, which will be used to compute the AMS, and will not be used in classification.

-   The discrete variable `PRI_jet_num` denotes the amount of jets from each event and takes values in $\{0,1,2,3\}$.

-   We have multiple variables which are the angle of detection for some observation.

-   All other variables are either direct or indirect measurements and are continuous.

# Missing Data

## What is missing and why?

Below are the variables which contain undefined values. By convention it was provided to use with values `-999` which is out of range for every observation.

```{r,echo = FALSE}
variables_WithError <- filter(yank(summary_OfHiggs,"numeric"), complete_rate != 1)[1:3]
#use filter to find all columns which contain missing data
ve <- datatable(variables_WithError[1:3],options = list(pageLength = 11))
#generate a datatable with the error variables
ve
#print ve
```

Notice that every column besides `DER_mass_MMC` is a jet variable, and in those, we only have two values for `completion_rate`. In fact these correspond to different values of `PRI_jet_num`:

-   0 jets: All jet variables were missing data.

-   1 jet: only `PRI_leading_pt`,`PRI_leading_eta` and `PRI_leading_phi` have data.

-   2 or more jets: All jet variables have data.

The above result can be found in the handbook for the variables provided with the Kaggle challenge. Unfortunately `DER_mass_MMC` does not have such an explanation and may be a result of some event during measurement. However it is still assigned the same `-999` value as the other missing data.

## Impact of the Missing Data

Despite understanding the cause of (most of) our missing data, we still don't know the impact of it, the following section is dedicated to understanding the correlation between the missing data from each variable and its classification.

Below we compute the percentage of `NA` data in Background and Signal respectively. If this missing data is distributed uniformly across Background and Signal then the percentages should be very close.

```{r, echo = FALSE}
Background <- filter(higgs_data_na, Label == "b")[c(variables_WithError$skim_variable)]#filtering rows by background
Signal <- filter(higgs_data_na, Label =="s")[c(variables_WithError$skim_variable)]#filter rows by signal

missing_GivenB <- apply(Background,2,function(x){return(round(100*sum(is.na(x))/length(x),digits = 4))})#calculate percentage missing data for background and signal
missing_GivenS <- apply(Signal,2,function(x){return(round(100*sum(is.na(x))/length(x),digits = 4))})
#Compute the percentage of background and signal missing from each variable
df <- datatable(data.frame(missing_GivenS,missing_GivenB,missing_GivenB-missing_GivenS),col = c("Signal","Background","Difference"),caption = "% of Missing Background and Signal Data",options = list(pageLength = 11))
#generate a dataframe 
df
```

Notice that `Signal` consistently has $13-18 \%$ less missing data than `Background`. Considering the size of our dataset ($\approx 8 \times 10^5) this is statistically significant. This means that in both the `DER_mass_MMC` and jet-variables cases, the amount of missing data is indicative of a classification. Meaning that including `-999` can help with classification and will not be removed.

# Variable Selection

## Co-Dependency of Data

We have the following algebraic codependencies:

-   `PRI_jet_all_pt = PRI_jet_leading_pt + PRI_jet_subleading_pt`

-   `PRI_lep_pt = DER_pt_ratio_lep_tau*PRI_tau_pt`

We can either remove `PRI_jet_all_pt` or remove both `PRI_jet_leading_pt` and `PRI_jet_subleading_pt` to reduce the dimension by $1$ or $2$. This same idea can be applied to to the other (multiplicative) dependence. Taking us down to possibly 26 dimensions.

Another 'dependence' is the fact that `PRI_jet_num` characterises the missing data in jet-variables. Meaning we could remove all of these in favour of keeping `PRI_jet_num` however this is very extreme and may produce detrimental effects.

## Density Plots

To get an understanding of the behavior of variable given their classification, we condition each variable on whether $y=b$ or $y=s$ respectively. The entire list can be found in the appendix but here are a few of note:

```{r, warning=FALSE,message = FALSE, echo = FALSE,fig.align="center",fig.width = 14,fig.height= 10}
source(here("R/variable_plots.R"))
#use variable plots to get plots, a function that returns densities plots for each variable given that it is b or s respectively, see R/variable_plots for more info
density_plots <- lapply(cols_ToPlot,plots)
#apply plots to our sample variables
plot_sample_densities <- ggarrange(plotlist = density_plots,ncol = 2, nrow = 2, align = "v", common.legend = TRUE)
#generate grid of plots
plot_sample_densities
```

 Some key takeaways from the density plots are:

-   We see that some these angle variables: `PRI_tau_phi`, `PRI_lep_phi`, `PRI_met_phi`, `PRI_jet_leading_phi`and `PRI_jet_subleading_phi` are approximately uniformly distributed and that there is very little variation between the classifications.

-   We have many distributions with distinct translations in their peaks: `DER_mass_MMC`, `DER_mass_transverse_met_lep`, `DER_mass_vis`, `PRI_tau_pt` and `DER_pt_ratio_lep_tau`.

-   Some distributions had higher variance in the background case (see `DER_deltar_tau_lep` or `PRI_tau_eta`), indicating they feel the difference, but may not be as useful for classification.

-   We can see that many jet-related variables are dominated by their `-999` values, additionally we see that the proportion of `-999` values is higher in the background case - as expected.

Variables with clear translational peaks make great contenders for classification, while jet-variables and ones with higher variance may need some sort of feature transform. We hypothesis that the uniform angle variables only provide noise to the problem and have no bearing on classification at all.

Before we decide on our preferences of variables, we employ an information theoretic technique to measure the impact of each variable: The Mutual Information.

## Performing Mutual Information Tests

For each variable $V$ we compute its mutual information with `Label`, variables with high mutual information are better indicators for classification. We hope this will validate our observations from plotting the data.

Our results are below, see the appendix for the exact values.
```{r,echo = FALSE, warning=FALSE,message = FALSE,fig.height= 10,fig.width= 10,fig.align = "center",results=FALSE}
source(here("R/Mutual_Information.R"))
#source mutual information file, which produces the mutual information for each variable, see file for more info
dt <- datatable(MI_Data_STORED_Ordered,col =c("Variable","Mutual Information"),
                options = list(pagelength=10))
#generate datatable with information in

Plot_Mutual_Information(MI_Data_STORED_Ordered)
```

Thankfully these results justify many of our direct observations from plotting the densities:

-   The variables with clear translational difference  in their peaks (`DER_mass_MMC`,`DER_mass_transverse_met_lep`,`DER_mass_vis`,`PRI_tau_pt` and `DER_pt_ratio_lep_tau`) had very high mutual information. Additionally, `DER_mass_MMC`: the only jet-variable with `-999` values, had the highest mutual information than any other variable, by a significant margin.

-   Variables which were around the middle in terms of mutual Information were a mixture of higher variance and jet-variables.

-   The mostly uniform variables ranked lowest in terms of mutual information.

## Principle Component Analysis
Here we use principle component analysis as a tool for visualization to build an intuition of the predictive power of our dataset when we include the missing data with the values left as -999 and don't include the variables with any data missing, respectively.
```{r,echo = FALSE, warning=FALSE,message = FALSE,fig.height= 3.5,fig.width= 10,fig.align = "center",results=FALSE}
source(here("R/pca_no_missing.R"))
plot_grid(PC1_PC2_2D,PC2_PC3_2D,PC1_PC3_2D,nrow=1)
```
```{r,echo = FALSE, warning=FALSE,message = FALSE,fig.height= 3,5,fig.width= 10,fig.align = "center",results=FALSE}
source(here("R/pca_missing_included.R"))
plot_grid(PC1_PC2_2D,PC2_PC3_2D,PC1_PC3_2D,nrow=1)
```

From these plots we can see that using the missing data gives us improved separability.
```{r scree, echo = FALSE, warning=FALSE, fig.align="center", fig.height=5, message=FALSE, warning=FALSE, results=FALSE}
source(here("R/pca_missing_included.R"))
plot_grid(scree_plot)
```

```{r,echo = FALSE, warning=FALSE,message = FALSE,fig.height= 18,fig.width= 10,fig.align = "center",results=FALSE}
source(here("R/pca_missing_included.R"))
plot_grid(PC1_var_contri,PC2_var_contri,PC3_var_contri,PC4_var_contri,nrow=4)
```
First, we can analyse the scree plot for the performed pca. This tells us that over 40% of the variance in the data was explained by PC1, but PC2, 3, & 4 all explain over 5% of the variance in the data each. We can see from the graphs of contribution from each variable to each principle component some more detail on what these PCs mean. 
PC1 through 3 are largely explaining the effect of the different types of missing data, this is expected since this data follows a particular pattern as discussed in previous sections. PC4 is dominated by the `DER_deltar_tau_lep` and `DER_mass_vis` and suggests a notably strong correlation between them as well as anti-correlation with `PRI_met`. Comparing this to the density plot of each variable we can see this might be picking out the subtler differences in the data such as the difference between background and signal.

## Conclusions on Variable Selection
After considering our multiple ways of prioritising these variables, we conclude that we will remove our variables heirarchically in the following order:

1) Include all variables

2) Remove all 4 algebraic co-dependencies and uniform variables (`PRI_lep_phi`, `PRI_met_phi`, `PRI_tau_phi`, `PRI_jet_leading_pt`, `PRI_jet_subleading_pt`, `DER_pt_ratio_lep_tau`, `PRI_tau_pt`).

3) |Remove bottom ten ranking mutual information variables.

4) Only use the top ten highest ranking mutual information variables (see above).

We note that one of our algebraic variables is `PRI_tau_pt`, which is in the top ten ranking - so that will be added back in. This allows us to cover both bases: removing significant algebraic codependence, and including variables which have high mutual information. The final choice is certainly a gamble, and is more an exercise is determining when the diminishing effects of dimension reducation take place.

# Fisher Discriminant Analysis

FDA creates an embedding that tells us how linearly separated our data can possibly be by maximizing between class scatterness and minimizing within class scatterness. This can be a useful aid to find out whether a linear classifier is appropriate and can additionally be used to see how removing variables affects the separability of our data.

```{r,echo = FALSE, warning=FALSE,message = FALSE,fig.width = 14,fig.height= 5}
source(here("R/fda.R"))
#source fda file, which computes fda for soem family of variables, and gives their scatter ratio, see file for more info
FDA_all <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_all_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_all) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA with all variables") +
  theme_bw()

#produce fda plot for all variables
FDA_codep_unif <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_drop_codep_unif_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_drop_codep_unif) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA without codependencies and uniform variables") +
  theme_bw()

#produce fda plot for dropping codependent and uniform variables
FDA_drop_mut_info <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_drop_mut_info_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_drop_mut_info) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA without lowest mutual information") +
  theme_bw()
  #produce fda plot for dropping the 10 lowest mutual information
FDA_mut_info <- ggplot() +
  geom_histogram(aes(x = fisher_discrim_mut_info_pred, y = stat(density), fill = Label),
                 data = fisher_discrim_higgs_vars_mut_info) +
  labs(x = expression(w^T * x)) +
  ggtitle("FDA with highest mutual information") +
  theme_bw()
#produce fda plot for top ten mutual information
plot_grid(FDA_all,FDA_codep_unif,FDA_drop_mut_info,FDA_mut_info,nrow = 2)
```

For these different FDA embeddings, we can compare the ratio between between class scatterness and within class scatterness:

```{r echo = FALSE}
datatable(
  data = data.frame(
    variables = c("All variables",
                  "Without codependencies and uniform variables",
                  "Without lowest mutual information",
                  "Highest mutual information"),
    scatter_ratio = c(scatter_ratio_all,
                      scatter_ratio_drop_codep_unif,
                      scatter_ratio_drop_mut_info,
                      scatter_ratio_mut_info)
  ),
  colnames = c("Variables included", "Scatter ratio")
)
#produce a datatable with each scatter ratio
```

We find that removing variables slightly lowers the linear separability of the data, but in general the values are comparable, particularly when comparing the scatter ratio of all variables with that removing the 10 lowest mutual information. Based on the plots, we can conclude that it is not possible to achieve a high degree of linear separability between the signal and background events with any of the variable sets, indicating that a non-linear feature transform is most likely appropriate.


# Support Vector Machines

We divided our dataset into a training and testing split, training SVMs on the training data and finding the AMS on the testing data.

```{r echo = FALSE, message=FALSE,warning = FALSE}
source(here("R/training_testing.R"))
#source training_testing file which generates training and testing data sets for SVM
```

By training SVMs with a linear kernel vs. a radial kernel on a 20% training set (using all predictor variables), we found that a radial kernel consistently yielded higher AMS:

```{r echo = FALSE}
fitted_svm_linear_all_20 <- readRDS(here("output/fitted_svm_linear_all_20.RDS"))
fitted_svm_radial_all_20 <- readRDS(here("output/fitted_svm_radial_all_20.RDS"))
#we ran our SVM code before knitting to save time, we simply take the results from our files
#for details see the SVM file
linear_ams_20 <- approx_median_sig(predictions = fitted_svm_linear_all_20,
                                   labels = higgs_testing_20$Label,
                                   weights = testing_weights_20)
radial_ams_20 <- approx_median_sig(predictions = fitted_svm_radial_all_20,
                                   labels = higgs_testing_20$Label,
                                   weights = testing_weights_20)
#compute the AMS from our SVM fit                                   
```

```{r echo = FALSE}
datatable(
  data = data.frame(
    kernel = c("Linear",
               "Radial"),
    AMS = c(linear_ams_20,
            radial_ams_20)
  ),
  colnames = c("Kernel", "AMS")
)
#dataframe for AMS
```

Based on these results, along with the results of FDA indicating that the dataset is not linearly separable, we moved forward using a radial kernel. We performed 5-fold cross-validation over the 20% training set to tune the two hyperparameters using a grid search: cost and $\gamma$ (bandwidth). We allowed cost to take on the values 0.5, 1, and 2 and $\gamma$ to take on the values 0.01, 0.1, and 0.5. Tuning was performed using our function `ams_tune_parallel`, which modifies the `e1071::tune` function to maximise AMS and to conduct cross-validation in parallel, dramatically improving the performance of tuning compared to the original package.

Below are the results of the hyperparameter tuning using four sets of variables: 1) Including all variables; 2) Removing the algebraic co-dependencies and uniformly distributed variables; 3) Removing the 10 variables with the lowest mutual information; 4) Using only the 10 variables with the highest mutual information.

```{r,echo = FALSE}
tune_params <- readRDS(here("output/tune_params.RDS"))
#take results from tuning params file
#see svm file for more info
datatable(
  tune_params,
  colnames = c("Variables included",
               "Cost",
               "Gamma")
)
#generate datatable
```

We then used the model using the best hyperparameter values from tuning to find the AMS value on the 80% testing dataset.

```{r echo = FALSE}
fitted_tuned_svm_radial_all <- readRDS(here("output/fitted_tuned_svm_radial_all_20.RDS"))
fitted_tuned_svm_radial_drop_codep_unif <- readRDS(here("output/fitted_tuned_svm_radial_drop_codep_unif_20_gc.RDS"))
fitted_tuned_svm_radial_drop_mut_info <- readRDS(here("output/fitted_tuned_svm_radial_drop_mut_info_20.RDS"))
fitted_tuned_svm_radial_mut_info <- readRDS(here("output/fitted_tuned_svm_radial_mut_info_20_2.RDS"))
#read results from files
all_ams <- approx_median_sig(predictions = fitted_tuned_svm_radial_all,
                             labels = higgs_testing_20$Label,
                             weights = testing_weights_20)
drop_codep_unif_ams <- approx_median_sig(predictions = fitted_tuned_svm_radial_drop_codep_unif,
                                         labels = higgs_testing_20$Label,
                                         weights = testing_weights_20)
drop_mut_info_ams <- approx_median_sig(predictions = fitted_tuned_svm_radial_drop_mut_info,
                                       labels = higgs_testing_20$Label,
                                       weights = testing_weights_20)
mut_info_ams <- approx_median_sig(predictions = fitted_tuned_svm_radial_mut_info,
                                  labels = higgs_testing_20$Label,
                                  weights = testing_weights_20)
#compute ams for all results
```

```{r echo = FALSE}
datatable(
  data = data.frame(
    kernel = c("All variables",
               "Without co-dependencies and uniform variables",
               "Without lowest mutual information",
               "Highest mutual information"),
    AMS = c(all_ams,
            drop_codep_unif_ams,
            drop_mut_info_ams,
            mut_info_ams)
  ),
  colnames = c("Variables included", "Testing AMS")
)
#datatable fo results
```

We see in the above data that removing the ten lowest mutual information produced the highest AMS when using an RBF kernel, followed by removing algebraic codependencies and the uniform variables. Using only the top ten highest mutual information actually yielded the lowest AMS, highlighting the trade-off between prioritizing high mutual information versus removing too many variables. 

# Appendix

### Mutual Information Results Table
```{r}
dt
```

### Density plots of each variable
The following are the density plots for our variables, conditioned on whether they are a detection of a higgs boson or not. Note that in the jet-variables and `DER_mass_MMC` we have peaks at `-999` which skew many of the variable plots.
```{r, warning=FALSE,message = FALSE, echo = FALSE,fig.align="center",fig.width = 14,fig.height = 35}
plot_list2 <- lapply(cols_ToPlot3,plots)
plot_sample_densities_orig <- ggarrange(plotlist = plot_list2,ncol = 2, nrow = 15, align = "v", common.legend = TRUE)

plot_sample_densities_orig
```
